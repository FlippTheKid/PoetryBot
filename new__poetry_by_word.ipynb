{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxo9nIhnTN9q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, urllib, itertools, shutil, random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import PIL\n",
        "import torch\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip Poetry.zip -d myfiles"
      ],
      "metadata": {
        "id": "EnXzFsmfTTHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip poems.csv.zip -d myfiles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzrJXHetMFbj",
        "outputId": "6343e5fe-f266-44d2-f00c-0e25d95e93f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  poems.csv.zip\n",
            "  inflating: myfiles/poems.csv       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydf = pd.read_csv(\"/content/myfiles/poems.csv\")"
      ],
      "metadata": {
        "id": "zFN7gyNbMMXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mydf[\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "XkPMXo88Mikc",
        "outputId": "e5771839-3343-4958-dff1-9da596d8b6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                      NaN\n",
              "1        На серебряные шпоры\\nЯ в раздумии гляжу;\\nЗа т...\n",
              "2        Пилигрим\\nАллах ли там среди пустыни\\nЗастывши...\n",
              "3        О, не скрывай! Ты плакала об нем –\\nИ я его лю...\n",
              "4        Ты знал ли дикий край, под знойными лучами,\\nГ...\n",
              "                               ...                        \n",
              "19311    Хорошо, что в этом мире\\nЕсть магические ночи,...\n",
              "19312    Пробочка над крепким иодом!\\nКак ты скоро пере...\n",
              "19313    Друзья, друзья! Быть может, скоро —\\nИ не во с...\n",
              "19314    Увы, дитя! Душе неутоленной\\nНе снишься ль ты ...\n",
              "19315    Изломала, одолевает\\nНестерпимая скука с утра....\n",
              "Name: text, Length: 19316, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>На серебряные шпоры\\nЯ в раздумии гляжу;\\nЗа т...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Пилигрим\\nАллах ли там среди пустыни\\nЗастывши...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>О, не скрывай! Ты плакала об нем –\\nИ я его лю...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ты знал ли дикий край, под знойными лучами,\\nГ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19311</th>\n",
              "      <td>Хорошо, что в этом мире\\nЕсть магические ночи,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19312</th>\n",
              "      <td>Пробочка над крепким иодом!\\nКак ты скоро пере...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19313</th>\n",
              "      <td>Друзья, друзья! Быть может, скоро —\\nИ не во с...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19314</th>\n",
              "      <td>Увы, дитя! Душе неутоленной\\nНе снишься ль ты ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19315</th>\n",
              "      <td>Изломала, одолевает\\nНестерпимая скука с утра....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19316 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "output_folder = 'output_files'\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "\n",
        "for index, row in mydf.iterrows():\n",
        "    filename = f'{index}.txt'\n",
        "    filepath = os.path.join(output_folder, filename)\n",
        "\n",
        "    with open(filepath, 'w', encoding='utf-8') as file:\n",
        "        file.write(str(row['text']))\n",
        "\n",
        "print(f\"Файлы успешно сохранены в папке '{output_folder}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EorCbWb_NxlC",
        "outputId": "a8d96d53-fb6f-4aee-d202-735e78555224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файлы успешно сохранены в папке 'output_files'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import json"
      ],
      "metadata": {
        "id": "3mg6tjTJTgUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODES = ['train', 'val', 'test']"
      ],
      "metadata": {
        "id": "245K46tgTgcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAIN_DIR = Path('/content/myfiles/Poetry/')\n",
        "TRAIN_DIR = Path('/content/output_files')\n",
        "files_list = list(TRAIN_DIR.rglob('*.txt'))"
      ],
      "metadata": {
        "id": "xL4aBu97Tges"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PoetryDataset(Dataset):\n",
        "  def __init__(self, files, mode):\n",
        "    super().__init__()\n",
        "    self.files = files\n",
        "    self.mode = mode\n",
        "    self.tokenizer = WordPunctTokenizer()\n",
        "\n",
        "    if not os.path.exists(\"word2vec_model.model\"):\n",
        "      self.train_word2vec()\n",
        "    with open('word_to_index_dict.json', 'r') as f:\n",
        "      loaded_dict = json.load(f)\n",
        "      self.word_to_index_dict = loaded_dict\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def loadtxt(self, file):\n",
        "    with open(file, 'r', encoding='utf-8') as text:\n",
        "      content = text.read()\n",
        "    return content\n",
        "\n",
        "\n",
        "  def preprocess_for_w2vec(self, content):\n",
        "    lines = content.split('\\n')\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "      if len(line) > 1:\n",
        "        line_tokens = self.tokenizer.tokenize(line.lower())\n",
        "        line_tokens = [token for token in line_tokens if token not in string.punctuation] # под сомнением\n",
        "        tokens.extend(line_tokens)\n",
        "\n",
        "        # if len(lines) > 0 and line != lines[-1]:\n",
        "        #   tokens.append(\"EOL\") # end of line token\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "  def train_word2vec(self):\n",
        "    sentences = []\n",
        "    all_tokens_set = set()\n",
        "    texts = [self.loadtxt(file) for file in self.files]\n",
        "    for text in texts:\n",
        "      sentence_of_text = self.preprocess_for_w2vec(text)\n",
        "      all_tokens_set.update(sentence_of_text)\n",
        "      sentences.append(sentence_of_text)\n",
        "\n",
        "    model_w2v = Word2Vec(sentences=sentences,\n",
        "                       min_count=1,\n",
        "                       vector_size=50,\n",
        "                       window=5,\n",
        "                       workers=4)\n",
        "\n",
        "    self.word_to_index_dict = {token: i for i, token in enumerate(all_tokens_set)}\n",
        "    self.word_to_index_dict[\"PAD\"] = len(self.word_to_index_dict)\n",
        "    with open('word_to_index_dict.json', 'w') as f:\n",
        "      json.dump(self.word_to_index_dict, f)\n",
        "    model_w2v.save(\"word2vec_model.model\")\n",
        "\n",
        "    return model_w2v\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      fileee = self.loadtxt(self.files[idx])\n",
        "      sequence_of_tokens = self.preprocess_for_w2vec(fileee)\n",
        "\n",
        "      inputs = sequence_of_tokens[:-1]\n",
        "      targets = sequence_of_tokens[1:]\n",
        "\n",
        "\n",
        "      sequence_of_indices_input = [self.word_to_index_dict.get(token) for token in inputs]\n",
        "      sequence_of_indices_target = [self.word_to_index_dict.get(target) for target in targets]\n",
        "\n",
        "      return {\"inputs\": torch.tensor(sequence_of_indices_input),\n",
        "            \"targets\": torch.tensor(sequence_of_indices_target)}"
      ],
      "metadata": {
        "id": "I9tKqo5LTghA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_files = list(TRAIN_DIR.rglob('*.txt'))\n",
        "train_dataset = PoetryDataset(train_val_files, mode='train')"
      ],
      "metadata": {
        "id": "iZb0-6U3Tgjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('word_to_index_dict.json', 'r') as f:\n",
        "    loaded_dict = json.load(f)"
      ],
      "metadata": {
        "id": "Ng4ThiMUTglm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(loaded_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0ouyKcoWi9N",
        "outputId": "abf7c808-45a5-4275-d98b-9667e87677e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255935"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ТЕПЕРЬ МОДЕЛЬКА**"
      ],
      "metadata": {
        "id": "98wBgyRiWmkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "mUr0t089W3Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PoetryLSTM(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(PoetryLSTM, self).__init__()\n",
        "    input_size = 50\n",
        "    hidden_size = 50\n",
        "    vectorizer = Word2Vec.load(\"word2vec_model.model\")\n",
        "    vocab_size = len(loaded_dict)\n",
        "    # предобученные в word2vec эмбеддинги\n",
        "    embedding_matrix = np.zeros((vocab_size, input_size))\n",
        "    for i in range(len(vectorizer.wv)):\n",
        "      word = vectorizer.wv.index_to_key[i]\n",
        "      if word in vectorizer.wv:\n",
        "        embedding_matrix[i] = vectorizer.wv[word]\n",
        "\n",
        "    self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32),freeze=False)\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=input_size,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=1,\n",
        "                            batch_first=True,\n",
        "                            dropout=0.2)\n",
        "\n",
        "    self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "      h0 = torch.zeros(1, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "      c0 = torch.zeros(1, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "\n",
        "      embedded_x = self.embedding(x)\n",
        "\n",
        "      lstm_out, (new_hidden_state, new_cell_state) = self.lstm(embedded_x, (h0, c0))\n",
        "      linear_layer_out_before_softmax = self.fc_out(lstm_out)\n",
        "\n",
        "      return linear_layer_out_before_softmax\n"
      ],
      "metadata": {
        "id": "Ntbo56PJWmDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ltsm_generator = PoetryLSTM()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = 10\n",
        "batch_size = 4\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model_ltsm_generator.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "print(device)\n",
        "model_ltsm_generator.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YZFhoKHWmGB",
        "outputId": "b0a1239d-8914-4b94-a96c-6ec21dbfc32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PoetryLSTM(\n",
              "  (embedding): Embedding(255935, 50)\n",
              "  (lstm): LSTM(50, 50, batch_first=True, dropout=0.2)\n",
              "  (fc_out): Linear(in_features=50, out_features=255935, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ТЕПЕРЬ DATALOADER + PADDING**"
      ],
      "metadata": {
        "id": "TLMxCpnlXFW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "9oiGZ8neWmKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate(batch):\n",
        "  max_seq_len = 50\n",
        "  inputs_batch_list = [item[\"inputs\"] for item in batch]\n",
        "  targets_batch_list = [item[\"targets\"] for item in batch]\n",
        "  padded_inputs = pad_sequence(inputs_batch_list, batch_first = True, padding_value = loaded_dict[\"PAD\"])\n",
        "  padded_targets = pad_sequence(targets_batch_list, batch_first = True, padding_value = loaded_dict[\"PAD\"])\n",
        "  mask = (padded_targets != loaded_dict[\"PAD\"]).float()\n",
        "  return {\"inputs\": padded_inputs[:, :max_seq_len],\n",
        "          \"targets\": padded_targets[:, :max_seq_len],\n",
        "          \"mask\": mask}"
      ],
      "metadata": {
        "id": "z_rztj8-XEb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True, collate_fn = custom_collate)"
      ],
      "metadata": {
        "id": "xXWXa9SWXEea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка на размерности\n",
        "\n",
        "it = iter(train_loader)\n",
        "batch = next(it)\n",
        "print(batch[\"inputs\"].size())\n",
        "print(batch[\"targets\"].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLdAw_aoXnZv",
        "outputId": "779c3341-72e0-4c5a-e987-487d16961d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 50])\n",
            "torch.Size([4, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(loaded_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-ySASQdcwjw",
        "outputId": "517c41bc-1d23-4ff1-8c2b-8fa1515759cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255935"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyU6AJC3YnON",
        "outputId": "388c44f7-c2b2-4ac5-dc95-c48f73340d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 18 18:50:14 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0             29W /   70W |   10216MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model_ltsm_generator.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs = batch[\"inputs\"].to(device).long()\n",
        "        targets = batch[\"targets\"].to(device)\n",
        "        mask = batch[\"mask\"].to(device)  # Маска для игнорирования паддинга\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output_probs = model_ltsm_generator(inputs)\n",
        "        output_probs_flat = output_probs.view(-1, output_probs.shape[-1])\n",
        "        targets_flat = targets.view(-1).long()\n",
        "\n",
        "        loss = criterion(output_probs_flat, targets_flat)\n",
        "        loss = (loss * mask.view(-1)).mean()  # Уч итываем маску\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch + 1}, Loss: {avg_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdPdyI8Q07Rn",
        "outputId": "4665b3f7-2089-470d-90ac-80cccb424d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.678112339642656\n",
            "Epoch 2, Loss: 4.3351950260096395\n",
            "Epoch 3, Loss: 4.134919483781626\n",
            "Epoch 4, Loss: 3.95751977825935\n",
            "Epoch 5, Loss: 3.8114296854295255\n",
            "Epoch 6, Loss: 3.675982125453708\n",
            "Epoch 7, Loss: 3.536171718077226\n",
            "Epoch 8, Loss: 3.4180729217375254\n",
            "Epoch 9, Loss: 3.2994628667485815\n",
            "Epoch 10, Loss: 3.2004805562362386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {value: key for key, value in loaded_dict.items()}"
      ],
      "metadata": {
        "id": "BeN57NdRnhAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(index_to_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPwI-8HJoijH",
        "outputId": "54db9479-f30f-42b6-f531-83d5215dfa01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255935"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word[136]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EFOxhGrLoapi",
        "outputId": "96eb5daa-b9d7-403c-8bf3-6f839b93aaa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'чудак'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_sequence, max_length, loaded_dict, index_to_word):\n",
        "    \"\"\"\n",
        "    Генерирует текст на основе начальной последовательности.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    input_indices = [loaded_dict.get(token) for token in start_sequence]\n",
        "\n",
        "\n",
        "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)\n",
        "\n",
        "    generated_text = list(start_sequence)  # Список сгенерированных слов\n",
        "\n",
        "    # return input_tensor\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for i in range(max_length):\n",
        "        output_linear = model(input_tensor)\n",
        "        # return output_linear[:, -1, :]\n",
        "        output_linear_flat = output_probs.view(-1, output_probs.shape[-1])\n",
        "        output_probs_last_step = torch.softmax(output_linear[:, -1, :], dim=-1)\n",
        "\n",
        "        top_k_indises = torch.topk(output_probs_last_step[0], k=25).indices\n",
        "\n",
        "        predicted_index = random.choice(top_k_indises)\n",
        "\n",
        "        predicted_word = index_to_word[predicted_index.item()]\n",
        "\n",
        "        generated_text.append(predicted_word)\n",
        "\n",
        "        input_tensor = torch.cat((input_tensor.to(device), torch.tensor([predicted_index]).unsqueeze(0).to(device)), dim=1).to(device)\n",
        "\n",
        "    return ' '.join(generated_text)\n"
      ],
      "metadata": {
        "id": "2eFq5dcsX6Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_sequnce_example = [\"любви\", \"надежды\", \"тихой\", \"славы\"]\n",
        "generated_poem = generate_text(model_ltsm_generator, start_sequnce_example, max_length=100, loaded_dict=loaded_dict, index_to_word=index_to_word)\n",
        "\n",
        "print(generated_poem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y-8zqDPjq-f",
        "outputId": "26cbd15f-4b08-461b-c513-55cd6752da25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "любви надежды тихой славы хочу тебя мне дороже судьбе меня всегда хочу быть может о ты ни что за ты хочешь любить о всех чуде мне хочется меня с людьми ли вечно друг мой удел ли за нас он ты меня но о ты мне больно всё былое уж нет нет их души любви их страстей а если тебя когда же мне мое не зови ты любил мой голос так не знает но всё же не зови любви души моей когда много раз в огне моей тебе зачем всегда за мною душа моя как сердце ты ль с собою милой на тебя под кровом\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3MZNdXZ7uBqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "любви надежды тихой славы дух своей тобой во мглу ищу когда она ли ее вдохновенья и ныне люблю я знаю за меня к иному душа любовь любовью тобой и к тебе готов ли верь зачем меня — она мой нежный — лишь взор из дальних дорог там — мы любим я весь вас для счастья тебя как и каждый миг на устах меня от сна … свет как то мы был только солнце он как странно все и тихо из сердца чтоб — не верь ль не друг как — как то к сердцу же дано !.. всё в тот и то это давно\n",
        "\n",
        "[ ]\n"
      ],
      "metadata": {
        "id": "Ud0zOPUCUy6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EybZF0zHrOSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "****"
      ],
      "metadata": {
        "id": "RbO1xvmWqeum"
      }
    }
  ]
}